# MetahumanAudio2Face
MetahumanAudio2Face

This plugin is a high-performance audio-driven lip-sync (Audio-to-Lip Sync) solution based on the Epic MetaHuman framework, specifically designed for Unreal Engine developers. It efficiently converts input WAV audio files or raw audio data streams into precise facial lip-sync animations and natural micro-expressions and subtle head motions (Head Motion) in real time during runtime, enabling MetaHuman characters to deliver highly lifelike and expressive speech interactions.

The plugin supports streaming output of animation data, allowing animations to be generated and applied incrementally as the audio plays. This significantly reduces latency, enhances responsiveness, and improves overall interaction fluidity, delivering a more natural and real-time visual experience for users. Whether used for virtual streamers, digital human dialogue systems, interactive storytelling, or real-time communication applications, the plugin provides stable, low-latency facial animation driving capabilities, empowering developers to rapidly build immersive virtual character experiences.

This plugin requires lip-sync server support. The download link is provided below. The plugin's server package and example project can be downloaded from: https://pan.baidu.com/s/1wfTw7ME6REBSLQWtnnHWOw?pwd=tktu#list/path=%2F

本插件是一款基于Epic MetaHuman框架的高性能音频驱动口型同步（Audio-to-Lip Sync）解决方案，专为虚幻引擎（Unreal Engine）开发者量身打造。它能够在运行时高效地将输入的WAV音频文件或原始音频数据流，实时转换为精准的面部口型动画数据以及自然的头部微表情与轻微动作（Head Motion），从而驱动MetaHuman角色实现高度拟人化、富有表现力的语音交互效果。

插件支持动画数据的流式返回（Streaming Output），可在音频播放过程中逐步生成并应用动画，显著降低延迟，提升响应速度与交互流畅度，为用户带来更加自然、实时的视觉体验。无论是用于虚拟主播、数字人对话系统，还是互动叙事与实时通信场景，该插件都能提供稳定、低延迟的面部动画驱动能力，助力开发者快速构建沉浸式虚拟角色应用。

该插件需要口型服务端支持，下载地址见下方。 该插件的服务端以及示例项目下载地址：https://pan.baidu.com/s/1wfTw7ME6REBSLQWtnnHWOw?pwd=tktu#list/path=%2F

